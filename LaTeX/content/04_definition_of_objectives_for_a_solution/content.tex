\newpage\section{Definition of Objectives for a solution}\label{sec:objectForSolution}

As described earlier, goals for solving the problem are described by requirements, which are established using the \enquote{requirement engineering} approach. Beginning with the \textit{Requirements Elicitation} phase, applications and frameworks are reviewed, which enable the conducting of experiments. Subsequently, a literature review is conducted to establish further requirements for the field of data analytics based on previous research. Information gathered in this step are then used in the \textit{Requirements Specification} step in order to specify requirements for the final artefact. These requirements are then validated in the \textit{Requirements Validation} phase.

\subsection{Requirements Elicitation}

This phase gathers information in order to discorver possible requirements for the final artefact. These requirements are discovered by analyzing applications and frameworks that were created to support experimental research in related fields and through a literature review of studies that have utilized experiments in the field of behavioral research in data analyitics.

\subsubsection{Existing Resources for Online Experiments}

In this section, just three different resources for conducting online experiments are presented and then analyzed. A small example experiment was implemented with each of the applications in order to find out the advantages and disadvantages of the respective resource. The goal of this section is to draw conclusions and define requirements from the applications that allow to design an artifact for the field of data analytics. The applications analyzed are resources recommended for experiments by the Columbia Experimental Laboratory for Social Sciences. The selection of resources analyzed in the course of this thesis is limited to applications that allow the implementation of interactive experiments. Resources or applications that are only suitable for conducting surveys or passive experiments were neglected.

\textbf{z-Tree} Zurich Toolbox for Readymade Economic Experiments:
z-Tree is a software componant which development started in 1998 by the University of Zurich. The software component was developed as a toolbox for conducting economic experiments. The technical set-up of z-Tree usually consists of a client/server architecture, where the experiment conducter runs a server and the test subjects participate via a client. In general, the program is written in C++ and requires a Windows operating system, making it compatable with around 28.59\% of devices (\cite{statcounter.2023}). Simultaneously, however, this architecture ties the experiment setup exclusevly to desktop computers. An installation on devices that run other operating system necessarily requires a virtual machine or similar measures. Furthermore, the possibilities to use graphical interfaces in experiments are extremely limited. The same is true for computer interfaces that have been developed after the 1990s. Thus, the experiments implemented with z-Tree are mostly limited to mouse and keyboard inputs, while also limiting the amount of meta data which can be collected. Although technically all interfaces, data sources or other programs could be integrated, a software component of this age represents a significantly greater challenge for most extensions than applications designed under new standards and technologies. This is especially critical for the data analytics field, which is driven by extremely recent developments. Adapting z-Tree to newer experiments can thus involve a very high programming effort. (\cite{Zurich.2023}, \cite{Fischbacher.2006}, \cite{Chen.2016}). Z-Tree is also a proprietary software which can be licensed for free, but it is not an open source software (\cite{Fischbacher.2006}). In conclusion, Z-Tree thus represents an outdated and extremely limiting software component, which is not suitable for experimental research in the area of behavioral research or data analytics.

\textbf{oTree} An open-source platform for laboratory, online, and field experiments:

oTree is a publicly accessible and web-driven software solution developed for the purpose of facilitating the implementation of dynamic experiments across diverse domains, including laboratory settings, online platforms, field studies, or any synergistic combinations thereof. One of the motivators for its development was to replace the outdated z-Tree of the University of Zurich. The newer oTree removed many of the restrictions of z-Tree, such as limited user interfaces, a Windows constraint, limited extensibility, and more. Another goal of oTree was to simplify the execution of field experiments in contrast to z-Tree. OTree is open source and based on the Python programming language. By default oTree supports simple interactive experiments, more complex experiments have to be implemented by Python, requiring programming expertise. Experiments implemented in oTree work exclusively via a client/server architecture, where the experiment performer has to set up a server and the experiment participants then participate in the experiment via any device using a browser. This has great advantages especially for field experiments where participants can be recruited via a customized web-link.Nevertheless, oTree requires a lot of technical programming expertise to setup and additional hardware in form of a server. Depending on the complexity of the experiment, the work that oTree saves the developer is therefore rather limited. At the same time, simple experiments still require a certain amount of technical know-how, making oTree unsuitable for quick experiments. These circumstances could lead to little use of oTree, especially in the area of data analytics (\cite{Chen.2016}). In conclusion, oTree is in principle a solid solution for performing experiments. In conclusion, oTree is in principle a solid solution for conducting experiments, but due to its high level of technical expertise and other limitations, it seems to be rather unsuitable as a basis for conducting experiments in the field of data analytics. Nevertheless, as requirements for the artifact which is designed in the course of this work, especially the properties which oTree wanted to improve over its predecessor zTree should be included. These are mainly related to the use of complex and up to date user interfaces, the deployment on non windows platforms, the open-source approach and the possibility to add own program code for the experiments.

\textbf{LIONESS Lab} a free web-based platform for conducting interactive experiments online:
LIONESS Lab constitutes a cost-free, web-based platform designed for the facilitation of interactive online experiments. It is developed by the Centre for Decision Research and Experimental Economics (University of Nottingham, UK) and the Chair of Economic Theory (University of Passau, Germany). Thus, Lioness Lab is not only a proprietary software solution but also requires special access for its use and emphasizes the conducting of field experiments. This is free of charge, but it depends entirely on the Universities in question to obtain it. At the same time, the publishers of LIONESS LAB repeatedly emphasize that their solution hardly requires any programming knowledge to perform experiments (\cite{Giamattei.2020}). A circumstance that can complicate the use of complex custome coding for complex experiments. In addition, this paradigm removes much of the complexity of the software from the coding level to the customizing level. A problematic circumstance since this limits the extensibility and basically does not reduce the perceived complexity (\cite{Chou.2008}). Other unique features of Max include the ability to reduce waiting time, spontaneously form groups, handle participant dropouts, and a so called \enquote{robotic} feature that mimics user input for testing purposes. Also, because of the way experiments can be conducted using the software, the focus of effort tends to be more on field experiments as well (\cite{Giamattei.2020}). In summary, LIONESS Lab is a platform that stands out due to a variety of functions, but unfortunately is not open source. At the same time, the extensibility of the platform is very questionable, which makes it a good choice for suitable experiments, but unfortunately unusable for more complex experiments. Requirements resulting from this application are mainly a focus on openness of the platform, the creation of different groups regarding the test subjects and the possibility to use unrestricted coding if needed.

In summary, the analysis of the three applications showed important insights into alternative attempts of an application or platform to perform experiments in related scientific fields. The resulting findings are included in the requirements for the final artefact. These include openness of the platform, the creation of different participant groups, advanced user interface capabilities, the possibilitie to run custom code and and the delivery of the artifact with a minimum of standard functionality for creating experiments.  Nevertheless, a closer look at the applications could also show reasons as to why such applications are not suitable for experimental research in the field of behavioral research in data analytics. Which is supported by the lack of usage of these applications in the literature search of section \ref{sec:identification_of_the_problem} and \ref{subsec:literature_review_requirements}.

\subsubsection{Studies in Data Analytics - A Literature Review }\label{subsec:literature_review_requirements}

In order to establish further requirements for an artifact that should support experiments in the field of data analytics, a literature search is conducted. The focus is on articles and studies that research in the area of behavioral research in data analytics. The goal of the literature review is to understand commonalities and challenges of studies and especially experiments in this area in order to establish requirements for the creation of the artifact. The collected literature was subjected to categorization and analysis. Due to the assumption that data analytics lies both in the fields of information systems and business administration the same databases where used as for the literature review in section \ref{sec:identification_of_the_problem}. Table \ref{literature_search_db} gives an overview of the databases used. By using the same databases as in section \ref{sec:identification_of_the_problem}, it is also ensured that the requirements are elicited based on the same general selection of literature as the original problem was identified with. The approach to the literature search, established in section \ref{sec:identification_of_the_problem}, was also used for this literature review, ensuring a thorough examination of relevant research while avoiding unnecessary altering the process of finding literature. Therefore, to maintain the integrity of the identified literature and to avoid repetition, a process was followed as described in the previous literature review (section \ref{sec:identification_of_the_problem}). Specifically, publications from journals were selectively considered, including those listed in the \textit{Senior Scholars' Basket of Journals} for Information Systems and the \textit{UT Dallas Top 100 Business School Research Rankings} for Business Administration. The full list of these journals can be found in the appendix. As for the previous literature review, in order to ensure the quality of the publications, only peer-reviewed articles were considered, while book reviews, editorials, and opinion pieces were excluded. In addition, "non-scientific" texts or publications that did not meet scientific criteria were excluded from the search. The research was further refined by carefully reviewing article abstracts, which ensured that the selected literature remained relevant to the topic of experimental research in data analytics. The abstracts were reviewed not only for the use of experiments in the study, but also for research designs that could have allowed hypothesis testing by experiment. This was done to counteract the effect of selection bias. Selection bias generally describes the effects of making assumption based on a sample size, which does not represent the full population (\cite{Heckman.2010}). A simple example of Selection Bias would be to calculate the average Disposable Income of families based on the annual tax bill. This experimental design would reduce the total population to taxpaying families and thus lead to potentially grossly inaccurate results, since families living below the taxable threshold would not be included in the study. For the same principle, studies in which no experiment was performed are included in the literature review. The goal of this thesis is to improve the process of experimental research in the field of data analytics in general, so considering only studies that already perform experiments would not be representative of the full field and would be prone to selection bias. It could be, for example, that certain circumstances, possibly the lack of an appropriate application, make it difficult to perform experiments. This fact would be completely lost if only studies that already perform experiments were considered.

The literature found in the search was then again used for a backward and forward search. The backward search was conducted using Google Scholar. In addition to this, articles from other journals were, in a second step, reviewed and included as well if they met the scientific requirements, were officially published and relevant to the topic. This process initially yielded 56 research publications. The results were then classified according to the research method they utilize and whether a qualitative or quantitative approach was used. The results of this classification are presented in table \ref{tab:secondLiteratureSearch}.

\begin{table}[htbp]
    \centering
    \begin{tabular}{ll}
    \hline
    \multicolumn{1}{|l|}{Research Method} & \multicolumn{1}{l|}{Total} \\ \hline
    \multicolumn{1}{|l|}{Case  Study}     & \multicolumn{1}{l|}{16}    \\ \hline
    \multicolumn{1}{|l|}{Interview}       & \multicolumn{1}{l|}{3}     \\ \hline
    \multicolumn{1}{|l|}{Experiment}      & \multicolumn{1}{l|}{10}    \\ \hline
    \multicolumn{1}{|l|}{Observation}     & \multicolumn{1}{l|}{3}     \\ \hline
    \multicolumn{1}{|l|}{Survey}          & \multicolumn{1}{l|}{17}    \\ \hline
    \multicolumn{1}{|l|}{Data Analysis}   & \multicolumn{1}{l|}{7}     \\ \hline
                                          &                            \\ \hline
    \multicolumn{1}{|l|}{Quantitative}    & \multicolumn{1}{l|}{34}    \\ \hline
    \multicolumn{1}{|l|}{Qualitative}     & \multicolumn{1}{l|}{32}    \\ \hline
    \end{tabular}
    \caption[Research Methods of second Literature review]{Research Methods of second Literature review}\label{tab:secondLiteratureSearch}
    \end{table}


\subsection{Requirements Specification}

\subsection{Requirements Validation}


Personen müssen aufgeklärt werden über das Experiment \cite{Dresch.2011}




%The findings from the analysis of other applications and measures that could have optimized the research process in the field of data analytics are fundamentally important for the creation of the artifact of this thesis. Therefore, after showing that there is a gap in the literature in the area of data analytics and especially the carrying out of experiments, in this part several already existing applications are presented which could have been used for carrying out experiments. The identified problem and the found literature gap are only further emphasized, since the question arises, if there have already been applications that are supposed to support the execution of experiments, why have they not been used in the field of data analytics. None of the literature analyzed above used any of the following applications. The following applications were taken from a list of for Resources for Online Experiments at Columbia University (\cite{Columbia.2023}).




