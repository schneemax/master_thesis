\section{Definition of Objectives for a solution}\label{sec:objectForSolution}

On the basis of the results of the previous section, the identified problems to be solved by the artifact are a gap in behavioral research in the field of data analytics and a gap in the number of experiments conducted in this field. At the same time, applications that are designed to be used to implement experiments have large capability gaps. For this reason, the artifact is designed to be implemented in the form of a software application which enables experimental research in the field of behavioral research in data analytics.

%\subsection*{Requirement Engineering}
In order to define an objective for a possible solution in form of a software application requirements must be engineered (\cite{Seacord.2003}). Requirements can be classified according to ISO/IEC 25000, respectively the quality model from ISO/IEC 25010, as quality criteria for software and systems.(\cite{ISOIEC25010.2011}). The \ac{ieee} defines requirements as:
\begin{quote}
    \textbf{\textit{\enquote{(1) A condition or capability needed by a user to solve a problem or achieve an objective. (2) A condition or capability that must be met or possessed by a system or system component to satisfy a contract, standard, specification, or other formally imposed documents. (3) A documented representation of a condition or capability as in (1) or (2). See also: design requirement; functional requirement; implementation requirement; interface requirement; performance requirement; physical equirement.}}} \cite{IEEE.1990}
\end{quote}  
According to these definitions, requirements can be generally defined as properties that need to be met in order to achieve an objective. In order to engineer and to provide a certain quality these requirements are established using the \textit{requirement engineering} approach for analysis and evaluation of requirements is utilized (\cite{SWEBOK.2004}, \cite{Sommerville.2011}). This approach has been shown to clearly contribute to software project successes in the past (\cite{Hofmann.2001}) and is therefore a suitable approach to define the objectives for a solution. The exact individual phases and steps of the \textit{requirement engineering} approach can vary from source to source and use case to use case. In general, however, all steps fall into one of three main categories, the \textit{Requirements Elicitation}, \textit{Requirements Specification} and \textit{Requirements Validation} (\cite{SWEBOK.2004}, \cite{Sommerville.2011}, \cite{Fernandes.2009}). In the first step, possible requirements and use cases are collected via a variety of sources like analyses, surveys, literature or interviews (\cite{Sommerville.2011}). This thesis utilizes a literature review in order to discover requirements. In the next step, the requirements are then specified and categorized. An important distinction being the difference between functional and non-functional requirements. In the \textit{Requirements Validation} step, the elicited requirements are then tested for their validity. This phase emphasis the reviewing of the requirements in order to find out whether these requirements are actually representive of the desired artefact (\cite{Sommerville.2011}). This is accomplished througt Validity, Consistency, Completeness, Realism, and Verifiability checks in conjunction with protoyping and testing the requirements (\cite{Sommerville.2011}).


%As a means to create any software solution or artefact, the specification of requirements are important(\cite{Seacord.2003}). 




%As described earlier, goals for solving the problem are described by requirements, which are established using the \enquote{requirement engineering} approach. Beginning with the \textit{Requirements Elicitation} phase, applications and frameworks are reviewed, which enable the conducting of experiments. Subsequently, a literature review is conducted to establish further requirements for the field of data analytics based on previous research. Information gathered in this step are then used in the \textit{Requirements Specification} step in order to specify requirements for the final artefact. These requirements are then validated in the \textit{Requirements Validation} phase.


%\subsection*{Functional and non functional Requirements}

\subsection{Requirements Elicitation}

This phase gathers information in order to discorver possible requirements for the final artefact. These requirements are discovered by analyzing applications and frameworks that were created to support experimental research in related fields and through a literature review of studies that have utilized experiments in the field of behavioral research in data analyitics.

\subsubsection{Studies in Data Analytics - A Literature Review }\label{subsec:literature_review_requirements}

In order to establish further requirements a second literature search is conducted, which focusses on articles and studies in the field of behavioral research in data analytics. The goal of this second literature review is to understand commonalities and challenges of studies and especially experiments conducted in the area of data analytics, in order to establish requirements for the creation of the artifact. %The collected literature was subjected to categorization and analysis. 
Due to the assumption that data analytics lies both in the fields of information systems and business administration the same databases where used as for the literature review in section \ref{sec:identification_of_the_problem}. Table \ref{literature_search_db} gives an overview of the databases used. By using the same databases as in section \ref{sec:identification_of_the_problem}, it is also ensured that the requirements are elicited based on the same general selection of literature as the original problem was identified with. The approach to the literature search, established in section \ref{sec:identification_of_the_problem}, was also used for this literature review, ensuring a thorough examination of relevant research while avoiding unnecessary altering the process of finding literature. Therefore, to maintain the integrity of the identified literature and to avoid repetition, a process was followed as described in the previous literature review (section \ref{sec:identification_of_the_problem}). Specifically, publications from journals were selectively considered, including those listed in the \textit{Senior Scholars' Basket of Journals} for Information Systems and the \textit{UT Dallas Top 100 Business School Research Rankings} for Business Administration. The full list of these journals can be found in appendix \ref{appendix:subsec:seniorScholar} and \ref{appendix:subsec:UTDallas}. As for the previous literature review, in order to ensure the quality of the publications, only peer-reviewed articles were considered, while book reviews, editorials, and opinion pieces were excluded. In addition, \enquote{non-scientific} texts or publications that did not meet scientific criteria were excluded from the search. The research was further refined by carefully reviewing article abstracts, which ensured that the selected literature remained relevant to the topic of experimental research in data analytics. The abstracts were reviewed not only for the use of experiments in the study, but also for research designs that could have allowed hypothesis testing by experiment. This was done to counteract the effect of selection bias. Selection bias generally describes the effects of making assumption based on a sample size, which does not represent the full population (\cite{Heckman.2010}). A simple example of Selection Bias would be to calculate the average Disposable Income of families based on the annual tax bill. This experimental design would reduce the total population to taxpaying families and thus lead to potentially grossly inaccurate results, since families living below the taxable threshold would not be included in the study. For the same principle, studies in which no experiment was performed are included in the literature review. The goal of this thesis is to improve the process of experimental research in the field of data analytics in general. Considering only studies that already perform experiments would not be representative of the full field and would therefore be prone to selection bias. It could be, for example, that certain circumstances, possibly the lack of an appropriate application, make it difficult to perform experiments. This fact would be completely lost if only studies that already perform experiments were considered. An adequate example of an article that falls into this category is Sebastian Krakowski, Johannes Luger and Sebastian Raisch's 2022 article \enquote{Artificial intelligence and the changing sources of competitive advantage}, in which they research how atrificial intelligence change the compatitive advantage by being substitues to humans in managerial tasks and decision making. For this purpose, they are examining data from chess tournaments that have already been held. However, the same research question could have been answered by conducting experiments with chess players instead of using historical data from tournaments. Remarkably, the authors seem to come to a similair conclusion, stayting further research in this area should be conducted through experiments (\cite{Krakowski.2022}). Furthermore, it should be noted that the focus of this literature review was not to outline the current state of research, but to identify as many appropriate articles as possible. For this reason, fewer search terms were used and articles from different subareas were generally admitted, as long as they are located in the larger context of data analytics or decision making. For this reason, a backwards and forwards search was also omitted.
The search terms used for this literature review are \enquote{Data Analytics}, \enquote{Decision Making} and \enquote{Big Data}. With these terms, the search process should be kept as broad as possible. As already mentioned, these terms were used to search the databases from appendix \ref{appendix:subsec:seniorScholar} and \ref{appendix:subsec:UTDallas} for matching articles. The search was furhter limited to articles written in the english language. The abstracts of all articles were then analyzed. The number of found articles for each database are displayed in Table \ref{tab:articlesFoundRequirement}. This table indicates how many articles per corresponding term are contained in the respective database, which were published in one of the relevant journals. In this way, a total of 19,955 articles were considered by inspecting their headline and, if applicable their abstracts. The other databases listed in the appendix (among others, AIS Electronic Library, ACM Digital Library, IEEE Xplore / Electronic Library, ProQuest) did not contain articles in the corresponding journals that could be found by using the search terms and are therefore not included in the table.

%The literature found in the search was then again used for a backward and forward search. The backward search was conducted using Google Scholar. In addition to this, articles from other journals were, in a second step, reviewed and included as well if they met the scientific requirements, were officially published and relevant to the topic. This process initially yielded 56 research publications. The results were then classified according to the research method they utilize and whether a qualitative or quantitative approach was used. The results of this classification are presented in table \ref{tab:secondLiteratureSearch}.

This process initially yielded 46 research publications, which were supplemented by articles from the previous literature review corresponding to the criteria. This resulted in a total number of 56 articles. The results were then classified according to the research method they utilize and whether a qualitative or quantitative approach was used. The results of this classification are presented in table \ref{tab:secondLiteratureSearch}. An important note at this point is that the number of articles using experiments does not contradict the gap identified in section \ref{sec:identification_of_the_problem}, since in this literature review specifically filtered for research articles that use experiments. Thereafter, the exact experimental setup of the articles was analyzed in order to discover requirements for their individual experiments and therefore for the artefact which is subject of thesis.

\begin{table}[htbp]
    \centering
    \small
    \begin{tabular}{ll}
    \hline
    \multicolumn{1}{l}{Research Method} & \multicolumn{1}{l}{Total} \\ \hline
    \multicolumn{1}{l}{Case  Study}     & \multicolumn{1}{c}{16}    \\ 
    \multicolumn{1}{l}{Interview}       & \multicolumn{1}{c}{3}     \\ 
    \multicolumn{1}{l}{Experiment}      & \multicolumn{1}{c}{10}    \\ 
    \multicolumn{1}{l}{Observation}     & \multicolumn{1}{c}{3}     \\ 
    \multicolumn{1}{l}{Survey}          & \multicolumn{1}{c}{17}    \\ 
    \multicolumn{1}{l}{Data Analysis}   & \multicolumn{1}{c}{7}     \\ 
                                            &                            \\ \hline
    \multicolumn{1}{l}{Quantitative}    & \multicolumn{1}{c}{34}    \\ 
    \multicolumn{1}{l}{Qualitative}     & \multicolumn{1}{c}{32}    \\ \hline
    \end{tabular}
    \caption[Research Methods for Literature Search on Requirements]{Research Methods for Literature Search on Requirements}\label{tab:secondLiteratureSearch}
    \end{table}

The requirements derived from this are included in Table A. As already mentioned, not only requirements of performed experiments were included, but also requirements of setups that would have been suitable for an experiment. The column \enquote{Proper} indicates whether a requirement was actually mentioned directly in the article and the column \enquote{Extra} whether this requirement would have had to be used theorethically if the study had conducted an experiment. As already explained, this should ensure that not only requirements that fit to already performed experiments are discovered, in order to counteracted selection bias.

    \begin{table}[htbp]
        \centering
        \small
        \begin{tabular}{lcclccc}
        \hline
        Requirement          & \multicolumn{1}{l}{Proper} & \multicolumn{1}{l}{Extra} & Requirement & \multicolumn{1}{l}{Proper} & \multicolumn{1}{l}{Extra} \\ \hline
        Reusable                                                  & 11                         & 0                         & Participant Data                                           & 24                         & 23                        \\
        Interoperability                                           & 1                          & 0                         & Displaying Information                                     & 22                         & 23                        \\
        Meta Data Collecting                                       & 8                          & 0                         & Different Groups                                           & 14                         & 2                         \\
        Post-Interview                                             & 2                          & 0                         & Additional Logic                                           & 12                         & 0                         \\
        Time-Flexibility                                           & 9                          & 0                         & Evaluation of Data                                         & 27                         & 22                        \\
        Multi-Source                                               & 1                          & 0                         & Participant Input                                          & 21                         & 25                        \\
        Vizualize Final Data                                       & 2                          & 0                         & Real-Time Exchange                                         & 3                          & 0                         \\
        Proactive System                                           & 2                          & 0                         & Distant Communication                                      & 18                         & 0                         \\
        Pre-Loading Data                                           & 1                          & 0                         & Selecting Data                                              & 2                          & 0                         \\
        Monitoring of Study                                        & 1                          & 0                         & Simplicity                                                  & 1                          & 0                         \\
        Debrefing Info                                             & 1                          & 0                         & & & & \\\hline
        \end{tabular}
        \caption[Requirements Uncatagorized]{Requirements Uncatagorized}\label{tab:requirementsRaw1}
        \end{table}


  %  \begin{table}[htbp]
  %      \centering
  %      \begin{tabular}{lcccc}
  %      \hline
  %      Requirement             & \multicolumn{1}{l}{Total} & \multicolumn{1}{l}{Proper} & \multicolumn{1}{l}{Extra} \\ \hline
  %      Participant Data                    & 47                        & 24                         & 23                        \\
  %      Displaying Information              & 45                        & 22                         & 23                        \\
  %      Different Groups                    & 16                        & 14                         & 2                         \\
  %      Additional Logic                    & 12                        & 12                         & 0                         \\
  %      Evaluation of Data                  & 49                        & 27                         & 22                        \\
  %      Participant Input                   & 46                        & 21                         & 25                        \\
  %      Real-Time Exchange                  & 3                         & 3                          & 0                         \\
  %      Distant Communication               & 18                        & 18                         & 0                         \\
  %      Selecting Data                      & 2                         & 2                          & 0                         \\
  %      Simplicity                          & 1                         & 1                          & 0                         \\ \hline
  %      \end{tabular}
  %      \caption[Requirements Uncatagorized 2/2]{Requirements Uncatagorized 2/2}\label{tab:requirementsRaw2}
  %      \end{table}

  %\subsubsection{Existing Resources for online Experiments}


  %oTree: Nevertheless, as requirements for the artifact which is designed in the course of this work, especially the properties which oTree wanted to improve over its predecessor zTree should be included. These are mainly related to the use of complex and up to date user interfaces, the deployment on non windows platforms, the open-source approach and the possibility to add own program code for the experiments.

  %Lionness Lab: Requirements resulting from this application are mainly a focus on openness of the platform, the creation of different groups regarding the test subjects and the possibility to use unrestricted coding if needed.

  \subsubsection{Further relevant reference resources}\label{subsec:furtherRequirements}

  In addition to already developed applications and the relevant articles themselves, this section includes other sources that can be derived into requirements. These sources and requirements mainly refer to external influencing factors or specifications. Only requirements that have not yet been established by the previous methods are included.  
  In their book on Empirical Educational Research, H. Reinders,H. Ditton and C. Gräsel describe, among other things, the structure and empirical theory in relation to experiments. An important part of conducting experiments, according to the authors, is to educate the subjects about the experiment and its benefits. Rather than explaining the design of the experiment, this involves explaining the actual benefits and goal of the experiment to the participants after it has been conducted (\cite{Gniewosz.2011}). As already mentioned in the theoretical part about the theory behind the execution of experiments, confounding variables have to be eliminated for the effective execution of experiments. Although some of these measures must be implemented on a case-by-case basis by the individual experimental setup itself, the artifact is intended to assist in this process when possible. Especially the measures \enquote{Parallelization of confounding variables of the test subjects}, \enquote{Randomization of confounding variables of the subjects} and \enquote{Control group} represent measures which can be supported by an artifact. For this reason, the requirements \enquote{Random or targeted assignment of test subjects} are included in the list of requirements. The creation of control groups via different participant groups is already included as a requirement from several sources. In addition, findings from the analysis of the alternative applications for conducting experiments from Section \ref{sec:identification_of_the_problem} are used to establish requirements. These include the use of complex and up to date user interfaces, the deployment on non windows platforms, the open-source approach and the possibility to add own program code for the experiments based on the analysis of z-Tree and oTree. Further requirements based on the analysis of Lionness Lab are openness of the platform, the creation of different groups regarding the test subjects and the possibility to use unrestricted coding.
  
  
  %These include openness of the platform, the creation of different participant groups, advanced user interface capabilities, the possibilitie to run custom code and and the delivery of the artifact with a minimum of standard functionality for creating experiments.

  %related to the use 

  

%  The analysis of the applications to conduct experiments in the previous section showed important insights into alternative attempts of an application or platform to perform experiments in related scientific fields. The resulting findings are included in the requirements for the final artefact. 


\subsection{Requirements Specification}\label{subsec:reqSpec}

%For this reason, the requirements for the artefact are derived from properties and characteristics of past studies in the field of data analytics. In addition, general requirements for experimental research are also taken into account. 

%These requirements are further divided into functional and non-functional requirements.

After the requirements have been discovered and roughly outlined in the previous section, they are concretely specified, organized and classified in this section. For this purpose, the requirements were specified concretely with explanation and categorized based on their task. At the same time, the requirements were classified into functional and non-functional requirements.  A functional requirement describes a function that a system or system component must be able to perform (\cite{IEEE.1990}). An example of a functional requirement would be the calculation of a pricetag in euros and in dollars. Non-functional characteristics describe on the other hand the behavior of a system (\cite{Seacord.2003}) and go thereby beyond the functional characteristics. Thus functional requirements describe what a system must be able to do and non-functional requirements describe how this should be done. Non-functional requirements also often describe the quality of the individual functions and can influence several other requirements (\cite{Balzert.2011}). An example of non-functional properties would be that the conversion from euros to dollars must be performed in \enquote{a few seconds}. Table \ref{tab:FuncRequirementsCat} contains the functional and Table \ref{tab:NonFuncRequirementsCat} the non-functional requirements. The requirements are composed of the requirements discovered in sections \ref{subsec:literature_review_requirements} and \ref{subsec:furtherRequirements} and are included together in the tables. Requirements derived from multiple sources and methods are also just listed once in the table. 


\begin{table}
    \centering
    \small
    \begin{tabular}{L{0.35\textwidth}L{0.59\textwidth}}
    \hline
    Requirement                     & Description \\ \hline
    \rowcolor[HTML]{C0C0C0} 
    Information                 &             \\ \hline
    F1.1 Displaying Information     & Information must be able to be displayed            \\
     & \\
    F1.2 Debrefing Info             & Debrifing Information must be able to be displayed           \\
    & \\ \hline
    \rowcolor[HTML]{C0C0C0} 
    Data Collecting             &             \\ \hline
    F2.1 Participant Data           & Basic data about the participants must be able to be collected           \\
    F2.2 Meta-Data                  & Meta data must be collected            \\
    & \\
    F2.3 Post-Interview             & It must be possible to collect data after the experiment            \\
    & \\  \hline
    \rowcolor[HTML]{C0C0C0} 
    Pre-Loading                 &             \\ \hline
    F3.1 Pre-Loading Data           & Data must be able to be pre-loaded            \\
    & \\
    F3.2 Selecting Data             & Data must be able to be pre-selected and deleted           \\
    & \\ \hline
    \rowcolor[HTML]{C0C0C0} 
    Experiment Setup            &             \\ \hline
    F4.1 Additional Logic           & Custom logic/program code can be executed within the artifact            \\
    F4.2 Participant Input          & The artefact enables user input            \\
    & \\
    F4.3 Proactive System           & The artifact can pro-actively propmt a user action           \\
    & \\ \hline
    \rowcolor[HTML]{C0C0C0} 
    Groups                      &             \\ \hline
    F5.1 Different Groups           & The artifact must allow the division of participants into different groups            \\
    F5.2 Communication of Groups    & The different groups must be able to interact with each other            \\ 
    F5.3 Targeted Assignment        & Groups of test subjects must be able to be created based on certain attributes like confounding variables. \\
    F5.4 Random Assignment          & Groups of test subjects must be able to be created based on random assignment \\ \hline
    \end{tabular}
    \caption[Functional Requirements Structured]{Functional Requirements Structured}\label{tab:FuncRequirementsCat}
    \end{table}


\begin{table}
    \centering
    \small
    \begin{tabular}{L{0.35\textwidth}L{0.59\textwidth}}
    \hline
Requirement                             & Description \\ \hline
    \rowcolor[HTML]{C0C0C0} 
    Time-space non-reliance     &             \\ \hline
    N1.1 Distand Communication      & The artifact can be used regardless of the location of the participant            \\
    N1.2 Time-Flexibility           & The artifact can be used independently of a given period of time            \\ \hline
    \rowcolor[HTML]{C0C0C0} 
    Data Postprocessing &             \\ \hline
    N2.1 Evaluation of Data         & The data can be retrieved in a suitable way for further processing and evaluation            \\
    N2.2 Vizualize Final Data       & The data can be retrieved in a suitable way for further visualization             \\ \hline
    \rowcolor[HTML]{C0C0C0} 
    Simplicity                  &            \\ \hline
    N3.1 Simplicity                 & The artefact is simple to use           \\
    & \\ \hline
    \rowcolor[HTML]{C0C0C0} 
    Reusable and Interoperable  &             \\ \hline
    N4.1 Reusable                   & Experiments with the artefact are easy to re-do           \\
    & \\
    N4.2 Interoperability           & The artefact is interoperable            \\
    & \\
    N4.3 Openness of Platform       & The artefact is open to changes and enhancements \\
    & \\ \hline
    \rowcolor[HTML]{C0C0C0} 
    Monitoring                  &             \\ \hline
    N5.1 Monitoring of Study        & The study conducted with the artefact can be monitored            \\ 
    & \\ \hline
    \rowcolor[HTML]{C0C0C0} 
    Pre-Loading                 &             \\ \hline
    N6.1 Multi-Source             & Data from multiple-sources must be pre-loaded            \\ 
    & \\ \hline
    \rowcolor[HTML]{C0C0C0} 
    Advanced User Interface   &             \\ \hline
    N7.1 Advanced User Interface  & The Artefact enables the usage of modern user interface components            \\ \hline
    \end{tabular}
    \caption[Non-Functional Requirements Structured]{Non-Functional Requirements Structured}\label{tab:NonFuncRequirementsCat}
    \end{table}
\newpage


\subsection{Requirements Validation}\label{subsec:requirement_validation}

In this section, the previously established requirements are validated. The criteria Validity, Consistency, Completeness, Realism, and Verifiability from the requirement engineering approach are used for this purpose. The validity criterion indicates whether the requirements imposed actually correspond to the intended functions. Since the requirements were drawn up by taking into account applications that have already been developed and studies that have already been carried out, it can be assumed that the requirements correspond more precisely to the functions that are actually required than if they had been drawn up by any stakeholders. In addition, the requirements were established using a clearly defined scientific process and by adding literature from the field which should also increase validity. Some of the requirements derived in subsection \ref{subsec:application_requirements} are also conform with requirements from subsection \ref{subsec:literature_review_requirements} and \ref{subsec:furtherRequirements}, indicating that the requirement search covers the problem to be solved very well. For these reasons, it is assumed with a high probability that the validity of the requirements is guaranteed. Moreover, the established requirements in Table A and B do not contradict each other, which means that the consistency criterion is also met. The \enquote{completeness} criterion, which describes whether the overall scope of the functions is covered by the requirements, is difficult to confirm. The reason for this is the open nature of the artifact, which should enable the improved execution of arbitrary experiments. Thus, the functional scope of the artifact is theoretically endless. Nevertheless, this criterion can be confirmed considering requirement F2.1. Requirement F2.1 ensures that additional logic and program code can be implemented within the artefact, which means that theoretically an infinite number of further functions can be implemented by the person performing the experiment (as far as these requirements can be implemented by a Turing-Complete programming language). As a result, the \enquote{Completness} criterion is also considered to be fulfilled. The criterion \enquote{realism} can also be confirmed. No requirement indicates that it could not be implemented technically. However, this point will be discussed in more detail in the implementation of the artifact. At this point in time, this point is considered to be fulfilled. The last criterion to confirm the validity of the requirements is the \enquote{Verifiability}, which describes whether the individual requirements are formulated in a way that they can be tested. An important point, since the artefact must be tested for all requirements following the \ac{dsr} approach. In order to be able to formally confirm the criterion, a test-case is therefore designed which checks the artifact against the requirements. This approach is also supported by the scientific literature for the validation of requirements and is later used in the \ac{dsr} approach to confirm the requirements (\cite{Sommerville.2011}).

\begin{table}[htbp]
    \centering
    \small
    \begin{tabular}{L{0.04\textwidth}L{0.7\textwidth}L{0.15\textwidth}}
    \hline
    ID  & Test Description                                                                                                                                     & Requirement                  \\ \hline
    T1  & A welcome and goodbye message is displayed                                                                                               & F1.1, F1.2                 \\
    & \\
    T2  & Participants are prompted to input their age at the beginning and prompted to input how the liked the experiment at the end              & F2.1, F2.3, F4.3, F4.2 \\
    & \\
    T3  & The information about how long the experiment took is collected                                                                          & F2.2                         \\
    & \\
    T4  & The sex and the weight of the participant is pre-loaded into the experiment from different files. The sex of the participant is deleted. & F3.1, F3.2, N6.1                         \\
    & \\
    T5  & A chess game is added as custom logic                                                                                                    &  F4.1, F4.2, F4.3         \\
    & \\
    T6  & Two groups are created, one of the groups is particularly chosen the other one randomly selected                                           & F5.1, F5.3, F5.4         \\
    & \\
    T7  & A chess turn is played by both parties not using the same device                                                                         & F4.2, F5.2, N1.1, N1.2         \\
    & \\
    T8  & The results of the experiment are retrieved and displayed in third party software                                                        & F2.2, N2.1, N2.2, N5.1                \\
    & \\
    T9  & The experiment is redone a second time and another experimental setup is implemented                                                     & N4.1                         \\
    & \\
    T10 & The experiment is conducted on different devices                                                                                         & N4.2                         \\
    & \\
    T11 & During the experiment the current state of the chess board is exported to the conducter of the experiment                                & N5.1                         \\ 
    & \\ \hline
    \end{tabular}
    \end{table}

The non-functional requirements simplicity, openness of platform and advanced user interface cannot be precisely tested by a test case due to their subjectivity. One way to counteract this would be to formulate the requirement more precisely and for example to replace \enquote{advanced user interface} with \enquote{a user interface that was developed in 2023} This would satisfy the verifiability criterion, but no longer the validity criterion, since this requirement is actually fairly subjective and the test might not capture the initial intention of the requirement. For this reason, the three requirements Simplicity, openess of platform and advanced user interface are valid requirements, but no test cases are included for them. Nevertheless, they are taken into account in the development of the artefact and finally evaluated as best as possible.

By successfully setting up these tests, the \enquote{Verifiability} criterion can thus also be confirmed. Thus, the established artifacts meet the criteria Validity, Consistency, Completeness, Realism, and Verifiability and are thus valid requirements for the artifact.


%The findings from the analysis of other applications and measures that could have optimized the research process in the field of data analytics are fundamentally important for the creation of the artifact of this thesis. Therefore, after showing that there is a gap in the literature in the area of data analytics and especially the carrying out of experiments, in this part several already existing applications are presented which could have been used for carrying out experiments. The identified problem and the found literature gap are only further emphasized, since the question arises, if there have already been applications that are supposed to support the execution of experiments, why have they not been used in the field of data analytics. None of the literature analyzed above used any of the following applications. The following applications were taken from a list of for Resources for Online Experiments at Columbia University (\cite{Columbia.2023}).




