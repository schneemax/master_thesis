\newpage\section{Evaluation of the solution}

To validate the developed prototype, the previously established test cases are verified for the individual requirements. The testing of the test cases provides information about the degree of fulfillment of the requirements. In addition, the fulfillment of requirements that could not be validated by test cases is considered. Subsequently, the usability of the \ac{ui} of the prototype is assessed.

\subsection{Prototype validation}
This section looks at the individual test cases from Section \ref{subsec:requirement_validation} and describes both their implementation and the degree to which they have been fulfilled. Furthermore, the fulfillment of requirements that cannot be confirmed by test cases is evaluated. 

\subsubsection*{T1: A welcome and goodbye message is displayed} 

The implementation of this test cas<e can be done without further development by utilizing the standard functionalities of the developed prototype. For this purpose, the Information Screen Activity is specified as the first and last step in the experiment data. Furthermore, a corresponding welcome and farewell text is stored in the experiment data. Figure \ref{fig:T1} shows that the functional requirements F1.1 and F2.1 to show information at the beginning of the experiment and to provide the participants with debrifing information can be completely fulfilled by the artefact.

\subsubsection*{T2: Participants are prompted to input their age at the beginning and prompted to input how the liked the experiment at the end}

To perform this test, the experiment data must also be adjusted first. For this, the questionnair step must be placed at the beginning and the end of the experiment step order within the experiment data. In addition, the participant data must contain the respective data as an empty field to be queried as an attribute, since the query of the questionnair process only queries for missing data. These data entries are \enquote{age} and \enquote{experiment feedback} as defined by the test case. The two screens on which the participants are asked for their age at the beginning of the experiment and for feedback on the experiment at its end are shown in Figure \ref{fig:T2}. The test T2 and thus the requirements F2.1, F2.3, F2.2 and F2.3 can thus be fulfilled.

\subsubsection*{T3: The information about how long the experiment took is collected}

To fulfill this test case, which checks requirement F2.2, the time necessary to perform the experiment is measured. For this, the lines of code from Listing \ref{t3a} can be used on the start activity. These store the start time of the experiment in the meta data in the experiment data. The experiment is then run and the code lines in Listing \ref{t3b} are called when the experiment is completed. These code lines retrieve the start time of the experiment from the experiment data and calculate the total elapsed time during the experiment using the current system time. This is then also stored in the meta data of the experiment data. Thus, the test case T3 can be completely fulfilled and consequently the requirement F2.2.

\subsubsection*{T4: The gender and the weight of the participant is pre-loaded into the experiment from different files. The gender of the participant is deleted}

For test case T4, which verifies requirement F3.2, the files to be read in are read via corresponding Java interfaces in the ParticipantData class. Java supports the import of a variety of different file formats (\cite{Ullenboom.2017}). At the same time, the read-in data can also be formatted or adapted. In test case T4, the gender and weight of the participants is read in and the information about the gender is then deleted.

\subsubsection*{T5: A chess game is added as custom logic}

In test case T5, a chessboard game is to be implemented following the study of X. This test case is intended to verify F2.1, F2.2 and F2.3 which deal with the implementation of custom logic. The chessboard serves as a proof of the functionality to implement custom logic in the application. Since the checkerboard is an experimental step that requires interaction with the user, this test case is implemented in the course of a new activity. This activity has to be added to the order of the activities in the experiment data to ensure that it is called. A screenshot of this activity is shown in figure \ref{fig:chess}. The detailed coding of this custom activity will not be discussed further, since it only serves to verify the requirements. Through this custom activity and the fact that Java is a Turing Complete programming language testcase T5 is fulfilled.

\subsubsection*{T6: Two groups are created, one of the groups is particularly chosen the other one randomly selected}

%the first one through putting the group into the respective participant data
%second through code within the use case:
Generally, groups are defined by adding a group ID (e.g. group A or group 1) in the user data. If the corresponding group assignment field is not filled, the assignment is performed automatically in the AllocateGroupsUseCase use case. The code snippet in Listing \ref{t6} shows the standard code that assigns the participants who have no group assignment to a random group. The corresponding group assignment is then stored in the previously empty attribute. The test case T6 and thus the requirements F4.1, F4.3 and F4.4 are verified. Furthermore, a customized or extended group assignment would be implemented in the AllocateGroupsUseCase use case.

\subsubsection*{T7: A chess turn is played by both parties not using the same device}

Test case T7 deals with the interaction between multiple participants. For this purpose, the chess game in test case T5 is to be played by several participants on different devices. The implementation of this test case lies in the corresponding activity itself. In this case in the ChessGameActivity. For this a client class is needed for sending the current game state and a server class for receiving and offering the current game state. These classes are nested as private classes in the activity itself. Listing A shows the code for the server class, Listing B the code for the client class and Listing C the initiation of both classes at the start of the chess game. The server and client are initiated using threads to ensure correct and fast communication between the two playing parties. In this way, after each move played, the current state of the board is sent via the client of one device to the server of the other device. Since this test case only serves as a proof-of-concept, Java sockets were used to implement the communication. These are characterized by their simplicity, but their functionality is limited, especially for modern applications. The use of third-party interfaces or externally hosted servers such as Firebase is therefore conceivable, depending on the requirements of the experiment (\cite{Google.2023b}). Communication between two experiment participants on different devices could be demonstrated by playing a chess move in each case. Test case T7 and thus requirements F4.2, N1.1 and N1.2 could thus be fulfilled and confirmed.

\subsubsection*{T8 :The results of the experiment are retrieved and displayed in third party software}

To fulfill test case T8 and thus verify requirements N3.1, N.3.2, meta data are exported from the application and then read into external software. As mentioned above, Android in combination with Java basically supports a variety of file formats for export. The export of the metadata is implemented in the LogMetaDataUseCase use case via the printOutMetaData method and is shown in Listing \ref{t8}. For simplicity and as a proof of concept in the course of this test case, meta data in the form of processing times for the experiment is exported as a CSV file. These are then read into Excel in the course of this test case and visualized using an Excel representation. Figure \ref{fig:Excel} shows this Excel graphic. In principle, however, the CSV file could be processed in any other way, provided that the software used for further processing supports CSV files. 

\subsubsection*{T9: The experiment is redone a second time and another experimental setup is implemented}

The re-execution of an experiment verifying the requirement N5.1 can be implemented by re-reading the same experiment data. For this purpose, a generic experiment procedure was set up as an example, the experiment data was copied and used to perform a second experiment with the help of the artifact. At the same time, care was taken to ensure that the data of the participants in the two sample experiments were different. The second example experiment was congruent with the first experiment in terms of structure and execution. Only due to the different participant data, other attributes were queried in the questionair activity.

%just change the experiment data

    %\begin{lstlisting}[language=java,label=t3b,lineskip={0pt}, caption=Collect time needed to conduct experiment (b), basicstyle=\scriptsize, captionpos=b]
    %ArrayList<String> steps = new ArrayList<String>();

    %steps.add("com.example.master_thesis.InfoScreenActivity");
    %steps.add("com.example.master_thesis.ChooseTestSubjectActivity");
    %steps.add("com.example.master_thesis.QuestionnaireActivity");
    %steps.add("com.example.master_thesis.ChessExperimentActivity");
%\end{lstlisting}

\subsubsection*{T10: The experiment is conducted on different devices}

To verify requirement F5.2 and confirm test case T10, the developed artifact was exported to several other Android devices. Originally tested during development, the artifact was on a Pixel 4 XL. Therefore, to verify this test case, the artifact was installed and tested on a Pixel 6 Pro. The individual acitvities on this device are shown in Figure \ref{fig:uiScreensPixel6}. Although the two devices have different hardware, software and screen sizes, the artifact can be used on both devices and does not show any errors or bugs. This means that test case T10 can be fulfilled.

%PIXEL 6 PRO API 30

\subsubsection*{T11: During the experiment the current state of the chess board is exported to the conducter of the experiment}

Test case T11 can be tested similarly to test case T7. For this purpose, a message about the current status of the experiment is sent to a server via a client class in the same way as in test case T7. In contrast to test case T7, no messages are sent back and forth, but only the current status of the experiment is exported to a monitor. Therefore, only one client class is needed in the application itself. The server to which the current status is sent can therefore take different forms, only the IP address of the server must be known and it must be able to process the client message. Analogous to test case T7, the implementation of this communication is also possible via other ways and means, should more complex functions be required that go beyond the capabilities of the Java sockets. Test case T11 and thus requirement N6.1 can thus be verified.


\subsubsection*{Remaining requirements}

In summary, all requirements could be verified with the help of the established test cases. One exception are the non-functional requirements N4.1 simplicity, N5.3 openness of platform and N8.1 advanced user interface, which cannot be verified by test cases due to their subjectivity. Nevertheless, as already discussed in section \ref{subsec:requirement_validation}, these requirements represent important specifications for the artifact. For this reason, the fulfillment of these non-functional requirements will be addressed as feasibly as possible without the use of test cases. For this purpose, the experience gained from the implementation of the artifact and the documentation on the individual technologies is used. Besides the fact that Android and Java are generally concidered to be simple beginner friendly technologies by the developer community, the best practice architecture that was implemented in the course of this application is a big indicator for the simplicity of the application. The individual functions and code modules have been divided into reusable UseCases and all user interface activities have been commulated into android activities. In addition, the implementation of new custom capabilities for individual experiments has been made extremely easy. For example, the definition of the experiment steps is realized through the experiment data and does not have to be implemented separately by program code. The implementation of custom experiments is also streamlined which makes it possible for the person performing the experiment to set up his experiment without having to worry about the basic framework. Despite the subjectivity of the "simplicity" requirement, the requirement N4.1 simplicity is considered to be fulfilled for the artefact due to the usage of technologies which are considered to be simple and beginner friendly, the reusable and streamlined best practice architecture and functionalities of the andoird application and the encapsulation of standard functionalities. 
Requirement N5.3 Openness of platform describes the openness of the artifact for changes and enhancements. In general, it could be shown in the already verified requirements that the artifact is extensible. By using the best practice architecture in combination with the general concept of object orientation on which Java is based, it is also possible to argue that the application can be easily enhanced.
In addition, to verify requirement N8.1, the artifact must enable the use of modern user interface componente. As already explained, this requirement is also a subjective but nevertheless important requirement for the artifact. In the user interfaces of the final artifact, the MaterialUI developed by Google is used. Google claims that the Material UI is distinguished from other user interface technologies by its Responsive Design, Motion and Animation, Consistency, Accessibility, Cross-Platform Support and other design-related features. Furthermore, MaterialUI is characterized by active development on the part of Google and is regularly provided with updates. Thus, the underlying UI technology that was used for the development of the artifact represents a UI technology that will deliver a modern user interface in 2023, and the regular updates by Google can be assumed to guarantee this circumstance in the long run. In summary, the N8.1 requirement is considered to be fulfilled as well as possible through the use of the MaterialUI interface in combination with its update guarantee (\cite{Google.2023c}, \cite{Google.2023}). 

In conclusion, all requirements could be verified using and fulfilling the corresponding test cases. In addition, it was possible to show argumentatively on the basis of various sources why all other requirements that cannot be substantiated by test cases are also considered to be fulfilled and verified. Hence, all requirements for the artifact are fulfilled and verified.

\subsection{App Performance and Usability}

After all the requirements for the artifact have been met and the functionality of the artifact has been demonstrated, this section briefly validates the UI of the application. As described in this thesis, the UI of the artifact was implemented based on the different processes that require user inputs. For this purpose, the respective activities in the said processes were used and implemented on the individual screens by the corresponding UI components of an Android application with Material UI design. The UI thus adheres to the proven and tested UI concepts of Google's Material UI design philosophy. Nevertheless, this part of the work is intended to test the rough layout and usability of the artifact's user interface. The goal of this section is not to identify the best possible or most beautiful UI, but to verify that the UI used is a usable interface. For this purpose, a paper prototype is built using the screenshots from the artifact with the help of SAP Build. This prototype will be sent to 50 business informatics students of a large German Dax software company. They have the task to click through the prototype. Both the clicks and the time needed to navigate through the individual screens and the prototype are measured. The goal of this small test is to verify that the UI of the prototype is basically usable. The test would show potential for improvement if some participants did not manage to click to the end of the paper prototype, took an unusually long time to do so, or clicked several times at a point that was not intended to be interact with. In total, 32 of the invited participants were able to take part in the study. The participants took part in the test anonymously, for this reason the names of the participants in Appendix \ref{appendix:heatmapTimes} are filled with placeholders. The participants spent an average of 23.9375 seconds to complete the paper prototype. The users' summarized clicks are shown in the heatmaps in Figure \ref{subfig:heatmapA}, \ref{subfig:heatmapB}, and \ref{subfig:heatmapC}. The results of the test do not indicate any serious negative design decisions. The average time it took the participants to click through the prototype is reasonable and the heatmap in Figure \ref{fig:heatmaps} does not show any unusual hotspots. In general, the user interface appears to be usable and did not present any major or new challenges to the participants of the test. Once more, it should be pointed out that this test only serves to verify that the activities from the processes in connection with Google Material UI result in a meaningful and usable user interface and that the usability properties claimed by Google about MaterialUI can be fulfilled in the context of the artifact. Nevertheless, the test shows that the user interface of the artifact is usable and, in combination with the claims made by Google about the MaterialUI, is considered sufficiently functional for the artifact. 


In summary, this section verified the developed artifact. The requirements placed on the artifact were checked with the help of test cases and other sources. All requirements for the artifact were met. In addition, the \ac{ui} designed from the identified process steps and Google's MaterialUI was tested using a user test. This showed that the artifact has a usable interface and that the individual Android activities have no obvious potential for improvement. 