\section{Identification of the Problem}\label{sec:identification_of_the_problem}

%This part of the thesis defines the problem to be solved by the \ac{dsr} approach. For this purpose, a literature review is conducted to find potential gaps in the field of data analytics and methods used in this field. Subsequently, applications and tools are examined, which had been intended to support the research process.

%In order to identify constrains on the research on data analytics a literature search is conducted. The main objective of it is to analyze the existing literature to find research gaps, particularities and interrelationships between literature. This is supposed to give insights into the current state of research and to find out which part of the research process on data analyitcs still has room for improvements. Consequently, relevant literature was identified and reviewed. Afterwards, the identified literature was categorized and analyzed. Initially, it was assumed that the topic of data analytics lies both in the field of information systems and business (\cite{Abbasi.2016}, \cite{Levina.2005}). For this reason, the literature search was mainly conducted in literature databases that focussed on these topics. The literature search was conducted using a keyword search.

%In order to ensure the quality of the identified literature initially, only publications from certain journals were considered. These journals consist of the \textit{Senior Scholars' Basket of Journals} and the \textit{UT Dallas Top 100 Business School Research Rankings}. The former includes journals in the area of information systems and the later includes journals in the area of business administration. A full list of keywords, databases and journals that were used is included in appendix \ref{appendix:A}. Furthermore, only peer-reviewed articles were taken into account. This was done to ensure the quality of the found publications and to additionally exclude book reviews, editorials and opinion statements. Moreover, other 'non-scholarly' texts or publications that did not meet scientific requirements were also not considered in the search. Secondly, the abstracts of the particular articles were inspected to narrow the search further. Consequently, literature that did not meet the topic of data analytics was excluded from the search. The literature found in the search was then used for a backward and forward search. During a backward search, all cited sources of an article are examined and during a forward search all the literature that cites the original article is examined (\cite{Webster.2002}). The backward search was conducted using Google Scholar. In addition to this, articles from other journals were, in a second step, reviewed and included as well if they met the scientific requirements, were officially published and relevant to the topic. This process yielded 35 research publications. The results were then assigned to different phases of the aforementioned information value chain, their content best represents. This was done to find literature gaps in the general process of data processing. Additionally, the identified literature was categorized by their research methodology in order to find patterns and similarities in the literature. 

%By mapping the literature found to the information value chain, parts of the data processing process that are over- or under-represented may become visible. From this, conclusions can be drawn about the current state of research. Furthermore, the categories \enquote{overspanning} and \enquote{other} were introduced in addition to the phases of the information value chain to represent literature that either fits multiple phases of the information value chain or none. Using this method leads to the results shown in the \enquote{First Search} column of table \ref{informationValueChainResults}.

This part of the thesis defines the problem to be solved by the \ac{dsr} approach. For this purpose, a literature review is conducted to find potential gaps in the field of data analytics and the methods used in this field. Subsequently, applications and tools intended to support the research process are examined.

To identify constraints in the research on data analytics, a literature search is conducted. The main objective is to analyze existing literature to find research gaps, particularities, and interrelationships between the literature. This is supposed to provide insights into the current state of research and determine which part of the research process on data analytics still has room for improvement. Consequently, relevant literature was identified and reviewed. Afterward, the identified literature was categorized and analyzed. Initially, it was assumed that the topic of data analytics lies in both the field of information systems and business (\cite{Abbasi.2016}, \cite{Levina.2005}). For this reason, the literature search was primarily conducted in literature databases that focused on these topics. The literature search was conducted using a keyword search.

To ensure the quality of the identified literature, initially, only publications from certain journals were considered. These journals include the \textit{Senior Scholars' Basket of Journals} and the \textit{UT Dallas Top 100 Business School Research Rankings}. The former includes journals in the area of information systems, and the latter includes journals in the area of business administration. A full list of keywords, databases, and journals used is included in appendix \ref{appendix:A}. Furthermore, only peer-reviewed articles were taken into account. This was done to ensure the quality of the found publications and to additionally exclude book reviews, editorials, and opinion statements. Moreover, other 'non-scholarly' texts or publications that did not meet scientific requirements were also not considered in the search. Secondly, the abstracts of the particular articles were inspected to narrow the search further. Consequently, literature that did not match the topic of data analytics was excluded from the search. The literature found in the search was then used for a backward and forward search. During a backward search, all cited sources of an article are examined, and during a forward search, all the literature that cites the original article is examined (\cite{Webster.2002}). The backward search was conducted using Google Scholar. In addition to this, articles from other journals were, in a second step, reviewed and included as well if they met the scientific requirements, were officially published, and were relevant to the topic. This process yielded 35 research publications. The results were then assigned to different phases of the aforementioned information value chain, representing their content best. This was done to find literature gaps in the general process of data processing. Additionally, the identified literature was categorized by its research methodology to find patterns and similarities in the literature. By mapping the literature found to the information value chain, parts of the data processing process that are over- or under-represented may become visible. From this, conclusions can be drawn about the current state of research. Furthermore, the categories \enquote{Overspanning} and \enquote{Other} were introduced in addition to the phases of the information value chain to represent literature that either fits multiple phases of the information value chain or none. Using this method leads to the results shown in the \enquote{First Search} column of table \ref{informationValueChainResults}.


\begin{table}[htbp]
    \centering
    \small
    \begin{tabular}{lcc}
    \hline
    \multicolumn{1}{c}{Information Value Chain}  & First Search & \multicolumn{1}{l}{Additional Search} \\ \hline
    Data                                         & 4            &                                       \\
    Information                                  & 3            &                                       \\
    Knowledge                                    & 21           &                                       \\
    Decisions                                    & 4            & 0                                      \\
    Actions                                      & 0            & 0                                      \\
    Overspanning                                 & 0            & 3                                     \\
    Other                                        & 3            &                                       \\ \hline
    \textbf{Total}                               & 35           & 3                                     \\ \hline
    \end{tabular}
    \caption{Results Assigned to the Information Value Chain}
    \label{informationValueChainResults}
    \end{table}

%Table \ref{informationValueChainResults} shows an overabundance of literature that got assigned to the \enquote{knowledge} phase of the information value chain. The significantly fewer entries for the other phases indicate less research on these sub-parts of the information value chain. However, it cannot be concluded that this underrepresentation is due to the fact that these phases are less relevant in the context of data analytics. For this, more literature would have to exist confirming that these areas are less important in the field of data analytics.
%The underrepresentation of the phases \enquote{data} and \enquote{information} could also be explained by the fact that these phases are more technology driven and therefore less researched in a data analytics context. In fact, the corresponding literature, which was assigned to these phases mainly consists of publications researching the technical possibilitties and application of data. Their main research object does not directly consist of any broader topics for companies or the application of Data Anayltics.Nonetheless, in total, seven individual publications could be found that fit into these two phases. In addition, these two phases (\enquote{data} and \enquote{information}) will be considered as one in the further thesis, since the literature which was assigned to these phases lies thematically very closely together. 

%Only four publications were assigned to the \enquote{decisions} phase and none to the \enquote{actions} phase. These results in particular call into question if the topic of behavioral research in data analytics has been extensively researched. The reason for this is the fact that data analytics is primarily a decision support method (\cite{Runkler.2020}). Therefore, an overabundance of literature delineating the decision-making process of data analytics should likely exist. This is compounded by the fact that no literature could be found that addressed overspanning issues, as no overarching theories could exist for an insufficiently studied topic. In order to ensure that the ratio of the literature found is based on the research state and not on the keyword search being biased in any way, a second literature search was conducted focussed on finding more literature that could be assigned to the \enquote{decisions} or \enquote{actions} phase. This was only done for these phases as these two are most relevant in the context of data analytics and because, in total, the least literature could be assigned to them (viewing \enquote{data} and  \enquote{information} together). This second keyword search was conducted with the goal of finding more literature that could be assigned to the phases \enquote{decisions} and \enquote{actions}. Therefore, a new set of keywords including \enquote{decision}, \enquote{decision making} and \enquote{action} were added to the existing set of keywords. Furthermore, the abstracts were examined with an emphasis on the aforementioned goal. The results of this second keyword search are represented in the \enquote{Additional Search} column of table \ref{informationValueChainResults}. A total number of three additional publications were identified using this second search. These three publications were all assigned to the \enquote{overspanning} category. Consequently, no additional literature that could be assigned to the phases \enquote{decisions} or \enquote{actions} could be identified. This further indicates the fact that the topic of boundaries in data analytics is not researched extensively. In order to further analyze the literature and to potentially draw further conclusions, the found literature was also categorized regarding the research method that was used. This categorization is presented in table \ref{researchMethod}.

Table \ref{informationValueChainResults} shows an overabundance of literature that was assigned to the \enquote{Knowledge} phase of the information value chain. The significantly fewer entries for the other phases indicate less research on these subparts of the information value chain. However, it cannot be concluded that this underrepresentation is due to the fact that these phases are less relevant in the context of data analytics. For this, more literature would have to exist, confirming that these areas are less important in the field of data analytics. The underrepresentation of the phases \enquote{Data} and \enquote{Information} could also be explained by the fact that these phases are more technology-driven and, therefore, less researched in a behavioral data analytics context. In fact, the corresponding literature, which was assigned to these phases, mainly consists of publications researching the technical possibilities and applications of data. Their primary research objective does not directly involve broader topics for companies or the application of data analytics. Nonetheless, in total, seven individual publications could be found that fit into these two phases. In addition, these two phases (\enquote{Data} and \enquote{Information}) will be considered as one in the further thesis since the literature assigned to these phases is thematically very closely related. Only four publications were assigned to the \enquote{Decisions} phase, and none to the \enquote{Actions} phase. These results, in particular, call into question whether the topic of behavioral research in data analytics has been extensively researched. The reason for this is the fact that data analytics is primarily a decision support method (Runkler, 2020). Therefore, an overabundance of literature delineating the decision-making process of data analytics should likely exist. This is compounded by the fact that no literature could be found that addressed overarching issues, as no overarching theories could exist for an insufficiently studied topic. In order to ensure that the ratio of the literature found is based on the research state and not on the keyword search being biased in any way, a second literature search was conducted, focused on finding more literature that could be assigned to the \enquote{Decisions} or \enquote{Actions} phase. This was only done for these phases as these two are most relevant in the context of data analytics and because, in total, the least literature could be assigned to them (viewing \enquote{Data} and \enquote{Information} together). This second keyword search was conducted with the goal of finding more literature that could be assigned to the phases \enquote{Decisions} and \enquote{Actions}. Therefore, a new set of keywords, including \enquote{Decision}, \enquote{Decision Making}, and \enquote{Action}, were added to the existing set of keywords. Furthermore, the abstracts were examined with an emphasis on the aforementioned goal. The results of this second keyword search are represented in the \enquote{Additional Search} column of table \ref{informationValueChainResults}. A total of three additional publications were identified using this second search. These three publications were all assigned to the \enquote{Overspanning} category. Consequently, no additional literature that could be assigned to the phases \enquote{Decisions} or \enquote{Actions} could be identified. This further indicates that the topic of boundaries in data analytics is not extensively researched.

To further analyze the literature and potentially draw further conclusions, the found literature was also categorized regarding the research methods used. This categorization is presented in table \ref{researchMethod}.

\begin{table}[htbp]
    \centering
    \small
    \begin{tabular}{llc}
    \hline
    \multicolumn{1}{l}{Research approach} & \multicolumn{1}{l}{Method} & \multicolumn{1}{l}{Number} \\ \hline
    Qualitative (22)                      & Case Study                 & 13                         \\
                                          & Interviews                 & 4                          \\
                                          & Experiments                & 2                          \\
                                          & Observation                & 3                          \\
    Quantitative (16)                     & Survey                     & 12                         \\
                                          & Data Analysis              & 6                          \\ \hline
    \end{tabular}
    \caption{Research Approach Used in the Literature}
    \label{researchMethod}
    \end{table}

%The distribution presented in table \ref{researchMethod} show significant discrepencies in the number of research methods used. Methods such as case studys and surveys are used more frequently than average in contrast to other methods. The least frequently used methodology is the experiment. This fact further indicates an insufficient exploration of the field of behavioral research in data analytics, as experiments are the most suitable method for researching the behavior of people (\cite{Gniewosz.2011}). In this context experiments are a particularly important tool for investigating causal relationships in research (\cite{Gniewosz.2011}). The lack of experimental research seems to have not only created a blind spot in the current state of knowledge, but also a permanent limitation for new research, which lacks existing knowledge as a foundation for new science. 
%Although current knowledge suggests that both behavioral and experimental research should be an integral part of data analytic research, the literature review of this section was able to show that both areas are extremely underrepresented in literature and research. This circumstance is further underlined by the fact that resources already exist to support experimental research in the field of behavioral science (\cite{Columbia.2023}), but none of the articles analyzed utilized them. These resources are discussed briefly below to highlight potential problems in their use.

%The following applications are resources recommended for experments by the Columbian Experimental Laboratory for Social Sciences (\cite{Columbia.2023}). The selection of resources analyzed in the course of this thesis is limited to applications that allow the implementation of interactive experiments. Resources or applications that are only suitable for conducting surveys or passive experiments were neglected. A small example experiment was implemented with each of the applications in order to find out the advantages and disadvantages of the respective resource and to identify potential challenges with them in the context of data analytics.

The distribution presented in table \ref{researchMethod} shows significant discrepancies in the number of research methods used. Methods such as case studies and surveys are used more frequently than average, in contrast to other methods. The least frequently used methodology is the experiment. This fact further indicates an insufficient exploration of the field of behavioral research in data analytics, as experiments are the most suitable method for researching the behavior of people (\cite{Gniewosz.2011}). In this context, experiments are a particularly important tool for investigating causal relationships in research (\cite{Gniewosz.2011}). The lack of experimental research seems to have not only created a blind spot in the current state of knowledge but also a permanent limitation for new research, which lacks existing knowledge as a foundation for new science. Although current knowledge suggests that both behavioral and experimental research should be an integral part of data analytic research, the literature review of this section was able to show that both areas are extremely underrepresented in literature and research. This circumstance is further underlined by the fact that resources already exist to support experimental research in the field of behavioral science (\cite{Columbia.2023}), but none of the articles analyzed utilized them. These resources are discussed briefly below to highlight potential problems in their use. The following applications are resources recommended for experiments by the Columbia Experimental Laboratory for Social Sciences (2023). The selection of resources analyzed in the course of this thesis is limited to applications that allow the implementation of interactive experiments. Resources or applications that are only suitable for conducting surveys or passive experiments were neglected. A small example experiment was implemented with each of the applications in order to find out the advantages and disadvantages of the respective resource and to identify potential challenges with them in the context of data analytics.

%(\cite{Columbia.2023})


%\textbf{z-Tree} Zurich Toolbox for Readymade Economic Experiments:
%The software component z-Tree was developed as a toolbox for conducting economic experiments. The technical set-up of z-Tree usually consists of a client/server architecture, where the experiment conducter runs a server and the test subjects participate via a client. In general, the program requires a Windows operating system, making it compatable with around 28.59\% of devices (\cite{statcounter.2023}). Simultaneously, however, this architecture ties the experiment setup exclusevly to desktop computers. Furthermore, the possibilities to use graphical interfaces in experiments are extremely limited. The same is true for computer interfaces that have been developed after the 1990s. Thus, the experiments implemented with z-Tree are mostly limited to mouse and keyboard inputs, while also limiting the amount of meta data which can be collected. These limitations are especially critical for the data analytics field, which is driven by extremely recent developments. Adapting z-Tree to newer experiments can thus involve a very high programming effort. (\cite{Zurich.2023}, \cite{Fischbacher.2006}, \cite{Chen.2016}). Z-Tree is also a proprietary software which can be licensed for free, but it is not an open source software (\cite{Fischbacher.2006}). In conclusion, Z-Tree thus represents an outdated and extremely limiting software component, which is not suitable for experimental research in the area of behavioral research or data analytics.

%\textbf{oTree} An open-source platform for laboratory, online, and field experiments:
%oTree is a publicly accessible, open-source and web-driven software solution developed for the purpose of facilitating the implementation of experiments and based on the python programming language. It removed many of the restrictions compared to the older z-Tree software component, such as limited user interfaces, a Windows constraint, limited extensibility and more. One of the main intentions of oTree is to facilitate the execution of field experiments. By default oTree supports simple interactive experiments. More complex experiments have to be implemented by Python, requiring programming expertise. Experiments implemented in oTree are implemented exclusively via a client/server architecture, where the experiment performer has to set up a server and the experiment participants then participate in the experiment via any device using a browser. This has great advantages especially for field experiments where participants can be recruited via a customized web-link. Nevertheless, this also requires a lot of technical programming expertise to setup additional hardware like a server. Depending on the complexity of the experiment, the work that oTree saves the developer is therefore rather limited. At the same time, simple experiments still require a certain amount of technical know-how, making oTree unsuitable for non-technically proficient individuals. In conclusion, oTree is in principle a solid solution for conducting experiments, but due to its high level of technical expertise and other limitations, it seems to be rather unsuitable as a basis for conducting experiments in the field of behavioral research in data analytics (\cite{Chen.2016}). 

%\textbf{LIONESS Lab} a free web-based platform for conducting interactive experiments online:
%LIONESS Lab constitutes a cost-free, web-based platform designed for the facilitation of interactive online experiments. It is developed by the Centre for Decision Research and Experimental Economics (University of Nottingham, UK) and the Chair of Economic Theory (University of Passau, Germany). Thus, Lioness Lab is not only a proprietary software solution but also requires special access for its use even though it is free of charge. At the same time, the publishers of LIONESS LAB repeatedly emphasize that their solution hardly requires any programming knowledge to perform experiments (\cite{Giamattei.2020}). A circumstance that can complicate the use of complex custom coding for complex experiments. In addition, this paradigm removes much of the complexity of the software from the coding level to the customizing level. A problematic circumstance since this limits the extensibility and basically does not reduce the perceived complexity (\cite{Chou.2008}). In conclusion, LIONESS Lab is a platform that stands out due to a variety of functions, but unfortunately is not open source. At the same time, the extensibility of the platform is limited, which makes it a good choice for suitable experiments, but unfortunately unusable for more complex experiments like behavioral research would require (\cite{Giamattei.2020}). 

%In summary, none of the presented applications could be used for experimental behavioral research in data analytics without significant drawbacks. Therefore, it can be concluded that one of the possible reasons for the lack of experimental behavioral research in data analytics is the lack of a suitable application or framework.

\textbf{z-Tree} Zurich Toolbox for Ready-made Economic Experiments:
The software component z-Tree was developed as a toolbox for conducting economic experiments. The technical setup of z-Tree usually consists of a client/server architecture, where the experiment conductor runs a server and the test subjects participate via a client. In general, the program requires a Windows operating system, making it compatible with around 28.59\% of devices (\cite{statcounter.2023}). Simultaneously, however, this architecture ties the experiment setup exclusively to desktop computers. Furthermore, the possibilities to use graphical interfaces in experiments are extremely limited. The same is true for computer interfaces that have been developed after the 1990s. Thus, the experiments implemented with z-Tree are mostly limited to mouse and keyboard inputs, while also limiting the amount of metadata that can be collected. These limitations are especially critical for the data analytics field, which is driven by extremely recent developments. Adapting z-Tree to newer experiments can thus involve very high programming effort (\cite{Zurich.2023}, \cite{Fischbacher.2006}, \cite{Chen.2016}). Z-Tree is also a proprietary software which can be licensed for free, but it is not an open-source software (\cite{Fischbacher.2006}). In conclusion, z-Tree thus represents an outdated and extremely limiting software component, which is not suitable for experimental research in the area of behavioral research or data analytics.

\textbf{oTree} An open-source platform for laboratory, online, and field experiments:
oTree is a publicly accessible, open-source, and web-driven software solution developed for the purpose of facilitating the implementation of experiments and based on the Python programming language. It removes many of the restrictions compared to the older z-Tree software component, such as limited user interfaces, a Windows constraint, limited extensibility, and more. One of the main intentions of oTree is to facilitate the execution of field experiments. By default, oTree supports simple interactive experiments. More complex experiments have to be implemented in Python, requiring programming expertise. Experiments implemented in oTree are conducted exclusively via a client/server architecture, where the experiment performer has to set up a server and the experiment participants then participate in the experiment via any device using a browser. This has great advantages, especially for field experiments where participants can be recruited via a customized web link. Nevertheless, this also requires a lot of technical programming expertise to set up additional hardware like a server. Depending on the complexity of the experiment, the work that oTree saves the developer is therefore rather limited. At the same time, simple experiments still require a certain amount of technical know-how, making oTree unsuitable for non-technically proficient individuals. In conclusion, oTree is, in principle, a solid solution for conducting experiments, but due to its high level of technical expertise and other limitations (\cite{Chen.2016}), it seems to be rather unsuitable as a basis for conducting experiments in the field of behavioral research in data analytics. 

\textbf{LIONESS Lab} A free web-based platform for conducting interactive experiments online:
LIONESS Lab constitutes a cost-free, web-based platform designed for the facilitation of interactive online experiments. It is developed by the Centre for Decision Research and Experimental Economics (University of Nottingham, UK) and the Chair of Economic Theory (University of Passau, Germany). Thus, Lioness Lab is not only a proprietary software solution but also requires special access for its use even though it is free of charge. At the same time, the publishers of LIONESS LAB repeatedly emphasize that their solution hardly requires any programming knowledge to perform experiments (\cite{Giamattei.2020}). A circumstance that can complicate the use of complex custom coding for complex experiments. In addition, this paradigm removes much of the complexity of the software from the coding level to the customizing level. A problematic circumstance since this limits the extensibility and basically does not reduce the perceived complexity (\cite{Chou.2008}). In conclusion, LIONESS Lab is a platform that stands out due to a variety of functions, but unfortunately is not open source. At the same time, the extensibility of the platform is limited, which makes it a good choice for suitable experiments, but unfortunately unusable for more complex experiments like behavioral research would require (\cite{Giamattei.2020}). 

In summary, none of the presented applications could be used for experimental behavioral research in data analytics without significant drawbacks. Therefore, it can be concluded that one of the possible reasons for the lack of experimental behavioral research in data analytics is the lack of a suitable application or framework.
